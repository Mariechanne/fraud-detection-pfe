# ğŸ“– Guide Utilisateur - SystÃ¨me de DÃ©tection de Fraude

## ğŸš€ DÃ©marrage Rapide

### Installation

```bash
# Cloner le projet
git clone https://github.com/Mariechanne/fraud-detection-pfe.git
cd fraud-detection-pfe

# Installer les dÃ©pendances
pip install -r requirements.txt

# VÃ©rifier l'environnement
python scripts/env_check.py
```

---

## ğŸ¯ Utilisation de l'Application Streamlit

### Lancer l'application

```bash
streamlit run app/streamlit_app.py
```

L'application s'ouvrira automatiquement dans votre navigateur Ã  l'adresse `http://localhost:8501`

### FonctionnalitÃ©s principales

#### 1. **Analyse de Transaction Unique** ğŸ”

- Entrez le **montant** et le **temps** de la transaction
- Cliquez sur **"Variables avancÃ©es"** pour saisir les features V1-V28 (optionnel)
- Utilisez le bouton **"âš¡ Charger Exemple"** pour tester avec une vraie fraude
- Cliquez sur **"ğŸ” Analyser"**

**RÃ©sultats affichÃ©s:**
- âœ…/ğŸš¨ PrÃ©diction (NORMALE ou FRAUDE)
- ğŸ“Š ProbabilitÃ© de fraude
- ğŸ¯ Niveau de risque (FAIBLE, MODÃ‰RÃ‰, Ã‰LEVÃ‰, CRITIQUE)
- ğŸ“ˆ Graphiques de score
- ğŸ” Top 5 facteurs influents (SHAP)

#### 2. **Analyse par Lot (CSV)** ğŸ“

**Format du fichier CSV:**
```csv
Amount,Time,V1,V2,V3,...,V28
100.50,500,0.1,-0.2,0.3,...,0.05
250.00,1200,-0.5,0.7,-0.1,...,0.12
```

**Colonnes requises:**
- `Amount` (obligatoire)
- `Time` (obligatoire)
- `V1` Ã  `V28` (optionnel, mis Ã  0 si absents)

**Utilisation:**
1. Cliquez sur **"SÃ©lectionner un fichier CSV"**
2. Uploadez votre fichier (max 100 000 lignes)
3. L'analyse dÃ©marre automatiquement

**RÃ©sultats:**
- ğŸ“Š RÃ©sumÃ© statistique
- ğŸ“ˆ 4 onglets de visualisation:
  - **DonnÃ©es complÃ¨tes** (fraudes surlignÃ©es en rouge)
  - **Fraudes dÃ©tectÃ©es** uniquement
  - **Distribution** des probabilitÃ©s
  - **Analyse par risque** (camembert + tableau)
- ğŸ’¾ Bouton de tÃ©lÃ©chargement du rapport CSV
- ğŸ—„ï¸ Archivage automatique dans `reports/predictions/`

#### 3. **Configuration** âš™ï¸

**Seuil de dÃ©cision (Sidebar):**
- Ajustez le curseur entre 0% et 50%
- Un seuil **plus bas** dÃ©tecte plus de fraudes (+ faux positifs)
- Un seuil **plus haut** rÃ©duit les faux positifs (- dÃ©tection)
- Le seuil optimal par dÃ©faut est **~7.3%** (85% Recall, 20% Precision)

**Archivage automatique:**
- âœ… ActivÃ© par dÃ©faut
- Sauvegarde chaque analyse dans `reports/predictions/`
- Index CSV maintenu dans `_index.csv`
- Conservation des 100 derniÃ¨res archives

---

## ğŸ› ï¸ Scripts en Ligne de Commande

### 1. EntraÃ®ner un nouveau modÃ¨le

```bash
python scripts/train_model.py \
  --data data/raw/creditcard.csv \
  --output models/my_new_model \
  --smote-strategy 0.2 \
  --random-state 42
```

**Arguments:**
- `--data`: Chemin vers le fichier CSV de donnÃ©es
- `--output`: Dossier de sortie pour le modÃ¨le
- `--smote-strategy`: StratÃ©gie de rÃ©Ã©quilibrage SMOTE (default: 0.2)
- `--random-state`: Seed pour la reproductibilitÃ© (default: 42)

**Sortie:**
- `models/my_new_model/pipeline.joblib` - Pipeline sklearn complet
- `models/my_new_model/metrics_valid.json` - MÃ©triques de validation
- `models/my_new_model/columns.json` - Colonnes attendues

### 2. PrÃ©dire sur de nouvelles donnÃ©es

**Sur un fichier CSV:**
```bash
python scripts/predict.py \
  --model models/rf_smote_final \
  --input data/new_transactions.csv \
  --output results/predictions.csv
```

**Sur une transaction unique:**
```bash
python scripts/predict.py \
  --model models/rf_smote_final \
  --amount 250.50 \
  --time 3600
```

**Arguments:**
- `--model`: Dossier contenant le modÃ¨le
- `--input`: Fichier CSV Ã  analyser (optionnel)
- `--output`: Fichier de sortie pour les rÃ©sultats (optionnel)
- `--amount`: Montant pour une transaction unique (optionnel)
- `--time`: Temps pour une transaction unique (optionnel)
- `--threshold`: Seuil de dÃ©cision personnalisÃ© (optionnel)

---

## ğŸ“Š InterprÃ©tation des RÃ©sultats

### Niveaux de Risque

| Niveau | ProbabilitÃ© | Action recommandÃ©e |
|--------|-------------|-------------------|
| ğŸŸ¢ **FAIBLE** | < 30% | Transaction normale, aucune action |
| ğŸŸ¡ **MODÃ‰RÃ‰** | 30-50% | Surveillance recommandÃ©e |
| ğŸŸ  **Ã‰LEVÃ‰** | 50-80% | VÃ©rification manuelle conseillÃ©e |
| ğŸ”´ **CRITIQUE** | > 80% | Investigation immÃ©diate requise |

### MÃ©triques du ModÃ¨le

- **PR-AUC (0.86)**: Performance sur donnÃ©es dÃ©sÃ©quilibrÃ©es - **EXCELLENT**
- **ROC-AUC (0.97)**: CapacitÃ© de discrimination - **EXCELLENT**
- **Recall (0.86)**: DÃ©tecte 86% des fraudes rÃ©elles - **BON**
- **Precision (0.20)**: 1 alerte sur 5 est une vraie fraude - **ACCEPTABLE**

### Explications SHAP

Les **valeurs SHAP** indiquent l'impact de chaque variable sur la prÃ©diction:

- **Valeurs positives (ğŸ”´)** : Augmentent la probabilitÃ© de fraude
- **Valeurs nÃ©gatives (ğŸŸ¢)** : Diminuent la probabilitÃ© de fraude
- **Features clÃ©s** : V4, V17, V14, V10, Amount

---

## ğŸ§ª Tests

Lancer les tests unitaires:

```bash
# Installer pytest si nÃ©cessaire
pip install pytest

# Lancer tous les tests
pytest tests/ -v

# Lancer un fichier de test spÃ©cifique
pytest tests/test_predictor.py -v
```

---

## ğŸ“ Structure des Fichiers

```
fraud-detection-pfe/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py          # Application web
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # DonnÃ©es brutes (gitignored)
â”‚   â””â”€â”€ processed/                 # DonnÃ©es prÃ©traitÃ©es (gitignored)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ rf_smote_final/            # ModÃ¨le entraÃ®nÃ© (gitignored)
â”‚       â”œâ”€â”€ pipeline.joblib
â”‚       â”œâ”€â”€ metrics_valid.json
â”‚       â””â”€â”€ columns.json
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb              # Exploration des donnÃ©es
â”‚   â””â”€â”€ 02_preparation.ipynb      # PrÃ©paration et modÃ©lisation
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ predictions/               # Archives des prÃ©dictions
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_model.py            # Script d'entraÃ®nement
â”‚   â”œâ”€â”€ predict.py                # Script de prÃ©diction
â”‚   â””â”€â”€ env_check.py              # VÃ©rification environnement
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ loader.py             # Chargement des artefacts
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ predictor.py          # PrÃ©dictions
â”‚   â”‚   â””â”€â”€ explainer.py          # Explications SHAP
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ validation.py         # Validation des donnÃ©es
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ plots.py              # Graphiques
â””â”€â”€ tests/                         # Tests unitaires
    â”œâ”€â”€ test_predictor.py
    â”œâ”€â”€ test_loader.py
    â””â”€â”€ test_validation.py
```

---

## â“ FAQ

**Q: L'application Streamlit ne dÃ©marre pas**
```bash
# VÃ©rifier que Streamlit est installÃ©
pip install streamlit

# VÃ©rifier la version de Python
python --version  # Doit Ãªtre >= 3.10
```

**Q: Le modÃ¨le n'est pas trouvÃ©**
- Assurez-vous que le dossier `models/rf_smote_final/` existe
- VÃ©rifiez que `pipeline.joblib` est prÃ©sent
- RÃ©entraÃ®nez le modÃ¨le avec `scripts/train_model.py`

**Q: Comment changer le seuil de dÃ©cision?**
- Dans l'app Streamlit: Utilisez le slider dans la sidebar
- En ligne de commande: Utilisez `--threshold 0.1` avec `predict.py`

**Q: Les tests Ã©chouent**
```bash
# Installer toutes les dÃ©pendances de test
pip install pytest scikit-learn imbalanced-learn

# VÃ©rifier l'installation
pytest --version
```

**Q: Comment obtenir le dataset Kaggle?**
1. TÃ©lÃ©chargez depuis: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
2. Placez `creditcard.csv` dans `data/raw/`
3. Le fichier doit contenir ~285k lignes

---

## ğŸ†˜ Support

Pour tout problÃ¨me ou question:
1. Consultez la documentation dans `scripts/README`
2. VÃ©rifiez les issues GitHub
3. Contactez l'Ã©quipe de dÃ©veloppement

---

**Version**: 3.0
**DerniÃ¨re mise Ã  jour**: Novembre 2025
