# ğŸ¤ Speech de PrÃ©sentation - DÃ©tection de Fraudes Bancaires par Machine Learning

**Auteure** : Marie Chandeste Melvina J. H. Medetadji Migan
**Formation** : Licence Professionnelle en Data Science pour la Gestion des Entreprises
**Encadrement** : M. DOUMI KARIM / M. KHALID BENABBESS
**Institution** : ESLSCA Paris â€“ Campus Rabat

---

## ğŸ“‘ Structure de la PrÃ©sentation

1. **Introduction et Contexte** (2 min)
2. **ProblÃ©matique et Objectifs** (2 min)
3. **DonnÃ©es et Exploration** (3 min)
4. **MÃ©thodologie et Pipeline ML** (5 min)
5. **RÃ©sultats et Performances** (5 min)
6. **DÃ©monstration de l'Application** (5 min)
7. **Architecture Technique** (3 min)
8. **Conclusion et Perspectives** (2 min)
9. **Questions/RÃ©ponses**

**DurÃ©e totale** : 25-30 minutes

---

## SLIDE 1 : Page de Titre

### ğŸ¯ Visuel
```
DÃ‰TECTION DE FRAUDES BANCAIRES
PAR MACHINE LEARNING

Projet de Fin d'Ã‰tudes
Licence Professionnelle en Data Science

Marie Chandeste Melvina J. H. Medetadji Migan
ESLSCA Paris â€“ Campus Rabat
DÃ©cembre 2025
```

### ğŸ“ Speech

> **Bonjour Ã  tous,**
>
> Je m'appelle Marie Chandeste Melvina Medetadji Migan, et je suis ravie de vous prÃ©senter aujourd'hui mon Projet de Fin d'Ã‰tudes intitulÃ© **"DÃ©tection de Fraudes Bancaires par Machine Learning"**.
>
> Ce projet s'inscrit dans le cadre de ma Licence Professionnelle en Data Science pour la Gestion des Entreprises Ã  l'ESLSCA Paris, Campus Rabat, sous l'encadrement de Messieurs DOUMI KARIM et KHALID BENABBESS.
>
> Dans un contexte oÃ¹ la fraude bancaire reprÃ©sente un enjeu majeur pour les institutions financiÃ¨res, avec des pertes estimÃ©es Ã  plusieurs milliards de dollars chaque annÃ©e, ce projet propose une solution innovante utilisant l'intelligence artificielle pour dÃ©tecter automatiquement les transactions frauduleuses en temps rÃ©el.

**Transition** : *CommenÃ§ons par comprendre le contexte et la problÃ©matique de ce projet.*

---

## SLIDE 2 : Plan de la PrÃ©sentation

### ğŸ¯ Visuel
```
ğŸ“‹ PLAN DE LA PRÃ‰SENTATION

1. Contexte et ProblÃ©matique
2. Objectifs du Projet
3. DonnÃ©es et Exploration
4. MÃ©thodologie ML
5. RÃ©sultats et Performances
6. DÃ©monstration Application
7. Architecture Technique
8. Conclusion et Perspectives
```

### ğŸ“ Speech

> **Voici le plan de ma prÃ©sentation.**
>
> Je vais d'abord vous prÃ©senter le **contexte** dans lequel s'inscrit ce projet et la **problÃ©matique** que nous cherchons Ã  rÃ©soudre. Ensuite, je dÃ©taillerai les **objectifs** que nous nous sommes fixÃ©s.
>
> Nous examinerons ensuite les **donnÃ©es** utilisÃ©es et leur exploration, avant de plonger dans la **mÃ©thodologie Machine Learning** mise en Å“uvre, notamment le pipeline complet de traitement.
>
> Je vous prÃ©senterai les **rÃ©sultats obtenus** et les **performances** de notre modÃ¨le, suivis d'une **dÃ©monstration pratique** de l'application web dÃ©veloppÃ©e.
>
> Enfin, je vous expliquerai l'**architecture technique** du projet avant de conclure avec les **perspectives d'amÃ©lioration**.

**Transition** : *CommenÃ§ons par le contexte.*

---

## SLIDE 3 : Contexte et ProblÃ©matique

### ğŸ¯ Visuel
```
ğŸ’³ CONTEXTE : LA FRAUDE BANCAIRE

ğŸ“Š Chiffres ClÃ©s
â€¢ Pertes mondiales : 28 milliards $ en 2024
â€¢ Croissance : +14% par an
â€¢ Temps de dÃ©tection moyen : 6-12 mois
â€¢ Impact : Confiance client, rÃ©putation, coÃ»ts

ğŸš¨ PROBLÃ‰MATIQUE

Comment dÃ©tecter automatiquement et en temps rÃ©el
les transactions frauduleuses dans un contexte
de dÃ©sÃ©quilibre extrÃªme des donnÃ©es ?

DÃ©fi : 0.17% de fraudes sur 284,807 transactions
```

### ğŸ“ Speech

> **Le contexte de ce projet est celui de la lutte contre la fraude bancaire.**
>
> Les chiffres sont alarmants : les pertes mondiales dues Ã  la fraude bancaire ont atteint **28 milliards de dollars en 2024**, avec une croissance annuelle de **14%**. Le temps moyen de dÃ©tection d'une fraude est encore de **6 Ã  12 mois**, ce qui est beaucoup trop long.
>
> Cette situation a des consÃ©quences graves : perte de confiance des clients, atteinte Ã  la rÃ©putation des banques, et bien sÃ»r, des coÃ»ts financiers considÃ©rables.
>
> **La problÃ©matique** Ã  laquelle nous sommes confrontÃ©s est la suivante : **Comment dÃ©tecter automatiquement et en temps rÃ©el les transactions frauduleuses ?**
>
> Le principal dÃ©fi rÃ©side dans le **dÃ©sÃ©quilibre extrÃªme des donnÃ©es**. Dans notre dataset, seulement **0.17% des transactions sont frauduleuses** sur un total de 284,807 transactions. Cela reprÃ©sente Ã  peine 492 fraudes pour 284,315 transactions normales.
>
> Un modÃ¨le naÃ¯f qui prÃ©dirait "normale" pour toutes les transactions aurait une prÃ©cision de 99.83%, mais serait totalement inutile en pratique car il ne dÃ©tecterait aucune fraude. C'est lÃ  que l'expertise en Data Science entre en jeu.

**Transition** : *Face Ã  cette problÃ©matique, quels objectifs nous sommes-nous fixÃ©s ?*

---

## SLIDE 4 : Objectifs du Projet

### ğŸ¯ Visuel
```
ğŸ¯ OBJECTIFS DU PROJET

1. ğŸ¤– DÃ©velopper un ModÃ¨le ML Performant
   â†’ Maximiser le Recall (taux de dÃ©tection)
   â†’ Maintenir un nombre acceptable de faux positifs
   â†’ GÃ©rer le dÃ©sÃ©quilibre des donnÃ©es

2. ğŸ’» CrÃ©er une Application Web Interactive
   â†’ PrÃ©diction en temps rÃ©el
   â†’ Analyse par lot (fichiers CSV)
   â†’ Interface intuitive pour non-techniciens

3. ğŸ” Garantir l'InterprÃ©tabilitÃ©
   â†’ Explications SHAP pour chaque prÃ©diction
   â†’ Transparence du modÃ¨le (IA responsable)

4. ğŸ“¦ Assurer la QualitÃ© et la MaintenabilitÃ©
   â†’ Architecture modulaire
   â†’ Tests unitaires (22 tests)
   â†’ Documentation complÃ¨te
```

### ğŸ“ Speech

> **Nous nous sommes fixÃ©s quatre objectifs principaux.**
>
> **Premier objectif : DÃ©velopper un modÃ¨le Machine Learning performant.** Notre prioritÃ© est de **maximiser le Recall**, c'est-Ã -dire le taux de dÃ©tection des fraudes rÃ©elles. Manquer une fraude peut coÃ»ter trÃ¨s cher, donc nous prÃ©fÃ©rons avoir quelques fausses alertes plutÃ´t que de laisser passer de vraies fraudes. Bien sÃ»r, il faut maintenir un nombre acceptable de faux positifs pour que le systÃ¨me reste utilisable. Et naturellement, nous devons gÃ©rer le dÃ©sÃ©quilibre extrÃªme des donnÃ©es.
>
> **DeuxiÃ¨me objectif : CrÃ©er une application web interactive.** Il ne suffit pas d'avoir un bon modÃ¨le, il faut qu'il soit accessible. Nous avons donc dÃ©veloppÃ© une application permettant la prÃ©diction en temps rÃ©el pour des transactions individuelles, l'analyse par lot via des fichiers CSV, le tout avec une interface intuitive accessible mÃªme aux non-techniciens.
>
> **TroisiÃ¨me objectif : Garantir l'interprÃ©tabilitÃ©.** Dans le domaine bancaire, il est crucial de comprendre pourquoi une dÃ©cision est prise. Nous avons intÃ©grÃ© des explications SHAP pour chaque prÃ©diction, offrant une transparence totale sur le fonctionnement du modÃ¨le. C'est un aspect essentiel de l'IA responsable.
>
> **QuatriÃ¨me objectif : Assurer la qualitÃ© et la maintenabilitÃ© du code.** Nous avons dÃ©veloppÃ© une architecture modulaire, Ã©crit 22 tests unitaires pour garantir la robustesse du code, et produit une documentation complÃ¨te pour faciliter l'Ã©volution future du projet.

**Transition** : *Voyons maintenant les donnÃ©es sur lesquelles nous avons travaillÃ©.*

---

## SLIDE 5 : DonnÃ©es UtilisÃ©es

### ğŸ¯ Visuel
```
ğŸ“Š DATASET : CREDIT CARD FRAUD DETECTION (KAGGLE)

ğŸ“ˆ CaractÃ©ristiques
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transactions totales : 284,807      â”‚
â”‚ Fraudes : 492 (0.17%)               â”‚
â”‚ Transactions normales : 284,315     â”‚
â”‚ PÃ©riode : 2 jours (septembre 2013)  â”‚
â”‚ Source : ULB Machine Learning Group â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”¢ Variables (30 features)
â€¢ Time : Temps Ã©coulÃ© depuis 1Ã¨re transaction
â€¢ V1-V28 : Features PCA (confidentialitÃ©)
â€¢ Amount : Montant de la transaction
â€¢ Class : Variable cible (0=normale, 1=fraude)

âš ï¸ DÃ©sÃ©quilibre : 1 fraude pour 578 transactions normales
```

### ğŸ“ Speech

> **Pour ce projet, nous avons utilisÃ© le dataset "Credit Card Fraud Detection" disponible sur Kaggle, fourni par l'ULB Machine Learning Group.**
>
> Ce dataset contient **284,807 transactions** effectuÃ©es sur une pÃ©riode de **2 jours en septembre 2013**. Parmi ces transactions, nous avons **492 fraudes**, soit seulement **0.17%** du total, et **284,315 transactions normales**.
>
> Le dataset comprend **30 variables** :
> - **Time** : le temps Ã©coulÃ© en secondes depuis la premiÃ¨re transaction
> - **V1 Ã  V28** : ce sont des features transformÃ©es par PCA pour des raisons de confidentialitÃ©. Nous ne connaissons pas leur signification originale, mais elles capturent les caractÃ©ristiques essentielles des transactions
> - **Amount** : le montant de la transaction en euros
> - **Class** : notre variable cible, qui vaut 0 pour une transaction normale et 1 pour une fraude
>
> Le dÃ©sÃ©quilibre est extrÃªme : **1 fraude pour 578 transactions normales**. C'est ce qui rend ce problÃ¨me particuliÃ¨rement intÃ©ressant et challengeant d'un point de vue Machine Learning.

**Transition** : *Comment avons-nous explorÃ© ces donnÃ©es ?*

---

## SLIDE 6 : Exploration des DonnÃ©es (EDA)

### ğŸ¯ Visuel
```
ğŸ” ANALYSE EXPLORATOIRE DES DONNÃ‰ES

ğŸ“Š Observations ClÃ©s

1. Distribution du Montant
   â†’ Fraudes : montants faibles Ã  moyens (< 400â‚¬)
   â†’ Normales : distribution plus large
   â†’ MÃ©diane fraude : 122â‚¬ vs 22â‚¬ normale

2. Distribution Temporelle
   â†’ Fraudes uniformes sur les 2 jours
   â†’ Pas de pattern horaire spÃ©cifique

3. Features PCA (V1-V28)
   â†’ V4, V10, V11, V12, V14, V17 : plus discriminantes
   â†’ Distributions trÃ¨s diffÃ©rentes fraude vs normale

4. QualitÃ© des DonnÃ©es
   âœ… Aucune valeur manquante
   âœ… Aucun doublon
   âœ… Types de donnÃ©es corrects
```

### ğŸ“ Speech

> **L'analyse exploratoire des donnÃ©es nous a rÃ©vÃ©lÃ© plusieurs insights importants.**
>
> **PremiÃ¨rement, concernant la distribution des montants** : Les fraudes concernent principalement des montants faibles Ã  moyens, gÃ©nÃ©ralement infÃ©rieurs Ã  400 euros. La mÃ©diane des montants frauduleux est de 122 euros, contre seulement 22 euros pour les transactions normales. Les fraudeurs semblent privilÃ©gier des montants qui n'attirent pas trop l'attention.
>
> **DeuxiÃ¨mement, sur le plan temporel** : Les fraudes sont distribuÃ©es de maniÃ¨re assez uniforme sur les deux jours d'observation. Nous n'avons pas identifiÃ© de pattern horaire spÃ©cifique, ce qui suggÃ¨re que les fraudeurs opÃ¨rent Ã  tous moments.
>
> **TroisiÃ¨mement, concernant les features PCA** : Bien que nous ne connaissions pas leur signification exacte, l'analyse statistique montre que certaines variables comme V4, V10, V11, V12, V14 et V17 sont particuliÃ¨rement discriminantes. Leurs distributions sont trÃ¨s diffÃ©rentes entre les fraudes et les transactions normales, ce qui en fait des prÃ©dicteurs importants pour notre modÃ¨le.
>
> **Enfin, sur la qualitÃ© des donnÃ©es** : Excellente nouvelle, nous n'avons aucune valeur manquante, aucun doublon, et tous les types de donnÃ©es sont corrects. Cela nous permet de nous concentrer directement sur la modÃ©lisation sans phase de nettoyage intensive.

**Transition** : *Passons maintenant Ã  la mÃ©thodologie que nous avons mise en place.*

---

## SLIDE 7 : MÃ©thodologie - Pipeline ML

### ğŸ¯ Visuel
```
ğŸ”¬ PIPELINE MACHINE LEARNING COMPLET

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SPLIT STRATIFIÃ‰                         â”‚
â”‚    Train (70%) / Valid (15%) / Test (15%)  â”‚
â”‚    â†’ Conservation du ratio 0.17% fraudes   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. PREPROCESSING                           â”‚
â”‚    StandardScaler sur Amount & Time        â”‚
â”‚    V1-V28 : dÃ©jÃ  normalisÃ©es (PCA)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. RÃ‰Ã‰QUILIBRAGE : SMOTE                   â”‚
â”‚    sampling_strategy = 0.2                 â”‚
â”‚    20% fraudes vs 80% normales (train)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. MODÃ‰LISATION + CROSS-VALIDATION         â”‚
â”‚    3 algorithmes testÃ©s (CV 5-fold)        â”‚
â”‚    â†’ Logistic Regression (baseline)        â”‚
â”‚    â†’ Random Forest (300 arbres)            â”‚
â”‚    â†’ XGBoost                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. OPTIMISATION DU SEUIL                   â”‚
â”‚    Maximiser Recall avec Precision â‰¥ 20%   â”‚
â”‚    Seuil optimal trouvÃ© : 0.0733 (7.33%)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ Speech

> **Notre mÃ©thodologie suit un pipeline Machine Learning rigoureux en 5 Ã©tapes.**
>
> **Ã‰tape 1 : Split stratifiÃ© des donnÃ©es.** Nous avons divisÃ© nos donnÃ©es en trois ensembles : 70% pour l'entraÃ®nement, 15% pour la validation, et 15% pour le test final. Le split est stratifiÃ©, ce qui signifie que nous conservons le ratio de 0.17% de fraudes dans chaque ensemble. C'est crucial pour Ã©viter qu'un ensemble ne contienne trop ou trop peu de fraudes.
>
> **Ã‰tape 2 : Preprocessing.** Nous appliquons un StandardScaler sur les variables Amount et Time pour les normaliser. Les variables V1 Ã  V28 sont dÃ©jÃ  normalisÃ©es car elles proviennent d'une transformation PCA, donc nous les laissons telles quelles.
>
> **Ã‰tape 3 : RÃ©Ã©quilibrage avec SMOTE.** C'est une Ã©tape clÃ©. SMOTE, pour Synthetic Minority Over-sampling Technique, crÃ©e des exemples synthÃ©tiques de la classe minoritaire (les fraudes) en interpolant entre des exemples existants. Nous utilisons un sampling_strategy de 0.2, ce qui signifie qu'aprÃ¨s SMOTE, notre ensemble d'entraÃ®nement contient 20% de fraudes et 80% de transactions normales. Attention : SMOTE est appliquÃ© **uniquement sur l'ensemble d'entraÃ®nement** pour Ã©viter toute fuite de donnÃ©es.
>
> **Ã‰tape 4 : ModÃ©lisation avec Cross-Validation.** Nous avons testÃ© trois algorithmes avec une validation croisÃ©e 5-fold : la RÃ©gression Logistique comme baseline, Random Forest avec 300 arbres, et XGBoost. La cross-validation nous permet d'obtenir des estimations robustes des performances et de vÃ©rifier la stabilitÃ© des modÃ¨les.
>
> **Ã‰tape 5 : Optimisation du seuil de dÃ©cision.** Par dÃ©faut, un classificateur prÃ©dit "fraude" si la probabilitÃ© dÃ©passe 50%. Mais avec des donnÃ©es dÃ©sÃ©quilibrÃ©es, ce n'est pas optimal. Nous avons donc optimisÃ© le seuil pour maximiser le Recall tout en maintenant une Precision d'au moins 20%. Le seuil optimal trouvÃ© est de **7.33%** : toute transaction avec une probabilitÃ© supÃ©rieure Ã  7.33% est classÃ©e comme fraude.

**Transition** : *Quels modÃ¨les avons-nous comparÃ©s et lequel avons-nous retenu ?*

---

## SLIDE 8 : Comparaison des ModÃ¨les

### ğŸ¯ Visuel
```
ğŸ“Š RÃ‰SULTATS CROSS-VALIDATION 5-FOLD

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ModÃ¨le           â”‚ ROC-AUC  â”‚ PR-AUC  â”‚ Recall  â”‚ Precision â”‚ F1-Score â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Log. Regression  â”‚ 0.98Â±0.01â”‚ 0.78Â±0.04â”‚ 88.7Â±2.5â”‚ 22.7Â±1.6 â”‚ 0.36Â±0.02â”‚
â”‚ ğŸ† Random Forest â”‚ 0.98Â±0.01â”‚ 0.86Â±0.02â”‚ 82.9Â±1.1â”‚ 87.0Â±3.1 â”‚ 0.85Â±0.01â”‚
â”‚ XGBoost          â”‚ 0.98Â±0.01â”‚ 0.85Â±0.02â”‚ 83.4Â±2.0â”‚ 81.7Â±3.5 â”‚ 0.83Â±0.02â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… MODÃˆLE RETENU : RANDOM FOREST
â†’ Meilleur PR-AUC (0.8646) â†’ Excellent pour dÃ©sÃ©quilibre
â†’ Meilleur F1-Score (0.848) â†’ Ã‰quilibre Recall/Precision
â†’ Plus faible variance (Â±1.1%) â†’ TrÃ¨s stable
â†’ Precision Ã©levÃ©e (87%) â†’ Peu de fausses alertes

ğŸ“ˆ VALIDATION SET (avec seuil optimisÃ© 7.33%)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ModÃ¨le           â”‚ DÃ©tectÃ©esâ”‚ ManquÃ©esâ”‚ F. Alertesâ”‚ Recall  â”‚ PR-AUC    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Log. Regression  â”‚ 62/74   â”‚ 12      â”‚ 248       â”‚ 83.78%  â”‚ 0.6594    â”‚
â”‚ ğŸ† Random Forest â”‚ 65/74   â”‚ 9       â”‚ 243       â”‚ 87.84%  â”‚ 0.8335    â”‚
â”‚ XGBoost          â”‚ 63/74   â”‚ 11      â”‚ 252       â”‚ 85.14%  â”‚ 0.8262    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ Random Forest dÃ©tecte +3 fraudes vs baseline, avec -5 fausses alertes
```

### ğŸ“ Speech

> **Nous avons comparÃ© trois modÃ¨les de maniÃ¨re rigoureuse avec une validation croisÃ©e 5-fold.**
>
> **Les rÃ©sultats de la cross-validation montrent que** :
> - Les trois modÃ¨les ont un ROC-AUC excellent autour de 0.98
> - Cependant, le **Random Forest se distingue clairement** avec un PR-AUC de **0.86**, significativement supÃ©rieur Ã  la rÃ©gression logistique (0.78)
> - Le F1-Score du Random Forest est Ã©galement le meilleur Ã  **0.85**
> - Surtout, le Random Forest montre la plus faible variance avec seulement Â±1.1% sur le Recall, ce qui indique un modÃ¨le trÃ¨s stable
>
> **Pourquoi le PR-AUC est-il si important ?** Le PR-AUC, ou Area Under Precision-Recall Curve, est LA mÃ©trique de rÃ©fÃ©rence pour les donnÃ©es dÃ©sÃ©quilibrÃ©es. Contrairement au ROC-AUC qui peut Ãªtre trompeur avec des classes dÃ©sÃ©quilibrÃ©es, le PR-AUC nous donne une vraie mesure de la capacitÃ© du modÃ¨le Ã  dÃ©tecter les fraudes.
>
> **Sur le validation set avec le seuil optimisÃ© Ã  7.33%**, le Random Forest dÃ©tecte **65 fraudes sur 74**, soit un Recall de **87.84%**. ComparÃ© Ã  la rÃ©gression logistique qui en dÃ©tecte 62, c'est **3 fraudes supplÃ©mentaires dÃ©tectÃ©es**. Et en bonus, nous avons **5 fausses alertes en moins** !
>
> Le PR-AUC du Random Forest sur le validation set est de **0.8335**, soit une amÃ©lioration de **+26% par rapport Ã  la rÃ©gression logistique**. C'est pour toutes ces raisons que nous avons retenu le **Random Forest comme modÃ¨le final**.

**Transition** : *Examinons maintenant les performances finales de notre modÃ¨le.*

---

## SLIDE 9 : RÃ©sultats et Performances Finales

### ğŸ¯ Visuel
```
ğŸ¯ PERFORMANCES FINALES - RANDOM FOREST

ğŸ“Š MÃ‰TRIQUES VALIDATION SET
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trique        â”‚ Valeur   â”‚ InterprÃ©tation                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ROC-AUC         â”‚ 0.973    â”‚ â­â­â­â­â­ Excellente discrimination   â”‚
â”‚ PR-AUC          â”‚ 0.833    â”‚ â­â­â­â­â­ Excellent (dÃ©sÃ©quilibre)    â”‚
â”‚ Recall          â”‚ 87.84%   â”‚ 65/74 fraudes dÃ©tectÃ©es (9 manquÃ©es)â”‚
â”‚ Precision       â”‚ 21.10%   â”‚ 65/308 alertes sont vraies          â”‚
â”‚ F1-Score        â”‚ 0.340    â”‚ Bon Ã©quilibre avec prioritÃ© Recall  â”‚
â”‚ Seuil optimal   â”‚ 0.0733   â”‚ 7.33% (optimisÃ© pour max Recall)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ­ MATRICE DE CONFUSION (42,721 transactions)
                    PrÃ©diction
                 Normale    Fraude
    RÃ©alitÃ©  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    Normale  â”‚  42,404   â”‚   243   â”‚  (0.57% faux positifs)
    (42,647) â”‚    TN     â”‚   FP    â”‚
             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    Fraude   â”‚     9     â”‚   65    â”‚  (87.84% dÃ©tection)
    (74)     â”‚    FN     â”‚   TP    â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… STABILITÃ‰ VALID â†” TEST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trique â”‚ Valid   â”‚ Test   â”‚ Î”    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ ROC-AUC  â”‚ 0.9729  â”‚ 0.9752 â”‚ âœ…   â”‚
â”‚ PR-AUC   â”‚ 0.8326  â”‚ 0.8404 â”‚ âœ…   â”‚
â”‚ Recall   â”‚ 87.84%  â”‚ 86.49% â”‚ âœ…   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

Pas de surapprentissage ! ğŸ‰
```

### ğŸ“ Speech

> **Voici les performances finales de notre modÃ¨le Random Forest.**
>
> **Les mÃ©triques sur le validation set sont excellentes** :
> - Un **ROC-AUC de 0.973**, ce qui est exceptionnel et signifie que le modÃ¨le discrimine trÃ¨s bien entre fraudes et transactions normales
> - Un **PR-AUC de 0.833**, qui est notre mÃ©trique phare pour ce problÃ¨me de donnÃ©es dÃ©sÃ©quilibrÃ©es. C'est un score excellent qui confirme la robustesse du modÃ¨le
> - Un **Recall de 87.84%**, ce qui signifie que nous dÃ©tectons **65 fraudes sur 74**. Seulement **9 fraudes nous Ã©chappent**
> - Une **Precision de 21.10%**, ce qui signifie qu'une alerte sur cinq est une vraie fraude. En production, cela signifie environ **243 fausses alertes** Ã  vÃ©rifier manuellement, ce qui est un volume raisonnable et acceptable pour une banque
> - Le **seuil optimal** a Ã©tÃ© fixÃ© Ã  **7.33%**, optimisÃ© pour maximiser le Recall
>
> **La matrice de confusion nous donne une vue complÃ¨te** :
> Sur 42,721 transactions dans le validation set :
> - **42,404 vrais nÃ©gatifs** : transactions normales correctement identifiÃ©es
> - **243 faux positifs** : seulement 0.57% des transactions normales sont signalÃ©es Ã  tort
> - **9 faux nÃ©gatifs** : les fraudes manquÃ©es, que nous cherchons Ã  minimiser
> - **65 vrais positifs** : les fraudes correctement dÃ©tectÃ©es
>
> **Point crucial : la stabilitÃ© entre validation et test.** Les performances sur le test set sont cohÃ©rentes avec celles du validation set : ROC-AUC de 0.9752, PR-AUC de 0.8404, Recall de 86.49%. Les mÃ©triques sont trÃ¨s proches, ce qui prouve qu'il n'y a **pas de surapprentissage**. Notre modÃ¨le gÃ©nÃ©ralise bien Ã  de nouvelles donnÃ©es.

**Transition** : *Maintenant, permettez-moi de vous montrer comment ce modÃ¨le est dÃ©ployÃ© dans une application concrÃ¨te.*

---

## SLIDE 10 : DÃ©monstration de l'Application - Vue d'Ensemble

### ğŸ¯ Visuel
```
ğŸ’» APPLICATION WEB STREAMLIT

[CAPTURE D'Ã‰CRAN : Interface complÃ¨te de l'application]

ğŸ¨ Composants Principaux
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“± SIDEBAR                                      â”‚
â”‚   â€¢ Configuration du seuil (slider 0-50%)       â”‚
â”‚   â€¢ Affichage des mÃ©triques du modÃ¨le           â”‚
â”‚   â€¢ Options d'archivage                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ” ONGLET 1 : TRANSACTION UNIQUE                â”‚
â”‚   â€¢ Formulaire de saisie (Amount, Time, V1-V28) â”‚
â”‚   â€¢ Bouton "Charger Exemple"                    â”‚
â”‚   â€¢ PrÃ©diction en temps rÃ©el                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“ ONGLET 2 : ANALYSE PAR LOT (CSV)             â”‚
â”‚   â€¢ Upload de fichier (max 100k transactions)   â”‚
â”‚   â€¢ Traitement par batch (5000 lignes)          â”‚
â”‚   â€¢ TÃ©lÃ©chargement des rÃ©sultats                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸš€ Technologies
â€¢ Framework : Streamlit 1.38+
â€¢ Visualisations : Plotly (interactif)
â€¢ ML : scikit-learn + SHAP
â€¢ DÃ©ploiement : Local / Cloud ready
```

### ğŸ“ Speech

> **Passons maintenant Ã  la dÃ©monstration de l'application web que nous avons dÃ©veloppÃ©e.**
>
> L'application est construite avec **Streamlit**, un framework Python moderne qui permet de crÃ©er rapidement des interfaces web interactives pour des applications de Data Science.
>
> **L'interface se compose de trois parties principales** :
>
> **La sidebar sur la gauche** contient la configuration :
> - Un slider pour ajuster le seuil de dÃ©cision entre 0 et 50%
> - L'affichage des mÃ©triques du modÃ¨le (PR-AUC, ROC-AUC, Recall, Precision)
> - Les options d'archivage automatique des prÃ©dictions
>
> **Le premier onglet "Transaction Unique"** permet d'analyser une transaction individuelle en temps rÃ©el :
> - Un formulaire de saisie pour le montant, le temps, et optionnellement les 28 variables PCA
> - Un bouton "Charger Exemple" qui prÃ©-remplit le formulaire avec une vraie transaction frauduleuse du dataset pour tester rapidement
> - La prÃ©diction s'affiche instantanÃ©ment avec la probabilitÃ© et le niveau de risque
>
> **Le second onglet "Analyse par Lot"** permet de traiter des fichiers CSV :
> - Upload de fichiers contenant jusqu'Ã  100,000 transactions
> - Traitement optimisÃ© par batch de 5,000 lignes pour gÃ©rer les gros volumes
> - TÃ©lÃ©chargement des rÃ©sultats avec toutes les prÃ©dictions
>
> L'application utilise **Plotly pour les visualisations interactives** et intÃ¨gre **SHAP pour l'explainability**. Elle est prÃªte pour un dÃ©ploiement local ou cloud.

**Transition** : *Voyons concrÃ¨tement comment fonctionne la prÃ©diction sur une transaction unique.*

---

## SLIDE 11 : DÃ©monstration - PrÃ©diction Transaction Unique

### ğŸ¯ Visuel
```
ğŸ” PRÃ‰DICTION TRANSACTION UNIQUE

[CAPTURE D'Ã‰CRAN : RÃ©sultat d'une fraude dÃ©tectÃ©e]

INPUT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Amount : 406.85 â‚¬                  â”‚
â”‚ Time : 79,265 secondes             â”‚
â”‚ V1-V28 : (values from real fraud)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OUTPUT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸš¨ FRAUDE DÃ‰TECTÃ‰E                             â”‚
â”‚                                                â”‚
â”‚ ProbabilitÃ© : 92.33%                           â”‚
â”‚ Niveau de risque : ğŸ”´ CRITIQUE                 â”‚
â”‚                                                â”‚
â”‚ [JAUGE VISUELLE : 92.33%]                      â”‚
â”‚ [BARRE DE PROBABILITÃ‰ avec seuil Ã  7.33%]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š TOP 5 FACTEURS INFLUENTS (SHAP)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Featureâ”‚ Valeur              â”‚ Impact   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ V4     â”‚ -2.312              â”‚ +0.524 ğŸ”´â”‚
â”‚ V17    â”‚ -1.856              â”‚ +0.389 ğŸ”´â”‚
â”‚ V14    â”‚ -8.142              â”‚ +0.312 ğŸ”´â”‚
â”‚ V10    â”‚ -15.430             â”‚ +0.287 ğŸ”´â”‚
â”‚ Amount â”‚ 406.85              â”‚ +0.156 ğŸ”´â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”´ Impact positif = Augmente le risque de fraude
ğŸŸ¢ Impact nÃ©gatif = RÃ©duit le risque de fraude
```

### ğŸ“ Speech

> **Permettez-moi de vous montrer un exemple concret de prÃ©diction.**
>
> Nous avons ici une transaction rÃ©elle du dataset :
> - **Montant : 406.85 euros**
> - **Time : 79,265 secondes**, soit environ 22 heures aprÃ¨s le dÃ©but de la pÃ©riode d'observation
> - Les valeurs V1 Ã  V28 proviennent d'une vraie fraude du dataset
>
> **Le rÃ©sultat de la prÃ©diction est sans appel** :
> - **ProbabilitÃ© de fraude : 92.33%**
> - **Classification : FRAUDE DÃ‰TECTÃ‰E**
> - **Niveau de risque : CRITIQUE** (reprÃ©sentÃ© en rouge)
>
> La jauge visuelle et la barre de probabilitÃ© montrent clairement que nous sommes **trÃ¨s largement au-dessus du seuil de 7.33%**. Cette transaction nÃ©cessiterait une investigation immÃ©diate en production.
>
> **Mais ce qui est vraiment puissant, c'est l'explainability avec SHAP.** Le tableau affiche les **Top 5 facteurs qui ont influencÃ© cette prÃ©diction** :
> - **V4 = -2.312** a l'impact le plus fort avec **+0.524** sur le score de fraude
> - **V17 = -1.856** contribue Ã©galement fortement avec **+0.389**
> - **V14**, **V10**, et le **montant de 406.85â‚¬** complÃ¨tent les facteurs influents
>
> Tous ces impacts sont **positifs** (en rouge), ce qui signifie qu'ils augmentent la probabilitÃ© de fraude. Si un analyste devait vÃ©rifier cette transaction, il saurait exactement quels aspects examiner en prioritÃ©.
>
> **C'est un exemple parfait d'IA responsable** : non seulement nous dÃ©tectons la fraude, mais nous expliquons pourquoi. Cela permet aux analystes humains de comprendre et valider les dÃ©cisions du modÃ¨le.

**Transition** : *L'application permet aussi d'analyser des volumes importants de transactions. Voyons comment.*

---

## SLIDE 12 : DÃ©monstration - Analyse par Lot (CSV)

### ğŸ¯ Visuel
```
ğŸ“ ANALYSE PAR LOT - FICHIER CSV

[CAPTURE D'Ã‰CRAN : Interface d'upload CSV + RÃ©sultats]

Ã‰TAPE 1 : UPLOAD
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“„ Fichier : transactions_2025.csv   â”‚
â”‚ ğŸ“Š Taille : 15,234 transactions      â”‚
â”‚ â±ï¸ Temps de traitement : 3.2 sec     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰TAPE 2 : RÃ‰SULTATS GLOBAUX
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Transactions normales : 14,987 (98.4%)   â”‚
â”‚ ğŸš¨ Fraudes dÃ©tectÃ©es : 247 (1.6%)           â”‚
â”‚                                             â”‚
â”‚ Niveaux de risque :                         â”‚
â”‚ ğŸŸ¢ FAIBLE : 14,823 (97.3%)                  â”‚
â”‚ ğŸŸ¡ MODÃ‰RÃ‰ : 164 (1.1%)                      â”‚
â”‚ ğŸŸ  Ã‰LEVÃ‰ : 183 (1.2%)                       â”‚
â”‚ ğŸ”´ CRITIQUE : 64 (0.4%)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰TAPE 3 : VISUALISATIONS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TAB 1 : DonnÃ©es complÃ¨tes (fraudes en ğŸ”´)  â”‚
â”‚ TAB 2 : Fraudes uniquement (247 lignes)    â”‚
â”‚ TAB 3 : Distribution des probabilitÃ©s      â”‚
â”‚ TAB 4 : Analyse par risque (pie chart)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“¥ EXPORT
â€¢ Bouton tÃ©lÃ©chargement â†’ CSV complet avec prÃ©dictions
â€¢ Archivage automatique dans reports/predictions/
â€¢ Index CSV pour traÃ§abilitÃ©
```

### ğŸ“ Speech

> **L'application permet Ã©galement d'analyser des volumes importants de transactions via des fichiers CSV.**
>
> **Le processus est trÃ¨s simple en trois Ã©tapes** :
>
> **Ã‰tape 1 : Upload du fichier.** L'utilisateur sÃ©lectionne son fichier CSV. Dans cet exemple, nous avons 15,234 transactions. Le traitement prend seulement **3.2 secondes** grÃ¢ce Ã  notre optimisation par batch de 5,000 lignes. L'application peut gÃ©rer jusqu'Ã  **100,000 transactions** en une seule fois.
>
> **Ã‰tape 2 : RÃ©sultats globaux.** L'application affiche immÃ©diatement un rÃ©sumÃ© :
> - **14,987 transactions normales** (98.4%)
> - **247 fraudes dÃ©tectÃ©es** (1.6%)
> - La rÃ©partition par niveau de risque : 97.3% Ã  risque FAIBLE, 1.1% MODÃ‰RÃ‰, 1.2% Ã‰LEVÃ‰, et 0.4% CRITIQUE
>
> Ces chiffres donnent une vue d'ensemble instantanÃ©e permettant Ã  un analyste de prioriser son travail : les 64 transactions critiques nÃ©cessitent une attention immÃ©diate, tandis que les 183 Ã  risque Ã©levÃ© peuvent Ãªtre vÃ©rifiÃ©es dans un second temps.
>
> **Ã‰tape 3 : Visualisations interactives.** Quatre onglets de visualisation :
> - **DonnÃ©es complÃ¨tes** : Tableau avec toutes les transactions, les fraudes surlignÃ©es en rouge pour faciliter l'identification visuelle
> - **Fraudes uniquement** : Vue filtrÃ©e sur les 247 fraudes pour analyse approfondie
> - **Distribution des probabilitÃ©s** : Histogramme montrant la rÃ©partition des scores de fraude, avec la ligne de seuil Ã  7.33%
> - **Analyse par risque** : Graphique en camembert et tableau dÃ©taillÃ© par niveau de risque
>
> **Export et traÃ§abilitÃ©** :
> - Un bouton permet de tÃ©lÃ©charger le CSV complet avec toutes les prÃ©dictions et probabilitÃ©s
> - L'application archive automatiquement chaque analyse dans le dossier `reports/predictions/` avec timestamp
> - Un fichier index CSV maintient la traÃ§abilitÃ© de toutes les analyses effectuÃ©es
>
> Cette fonctionnalitÃ© est particuliÃ¨rement utile pour le traitement batch de nuit ou pour analyser les transactions d'une journÃ©e complÃ¨te.

**Transition** : *Voyons maintenant l'architecture technique qui rend tout cela possible.*

---

## SLIDE 13 : Architecture Technique

### ğŸ¯ Visuel
```
ğŸ—ï¸ ARCHITECTURE MODULAIRE

fraud-detection-pfe/
â”œâ”€â”€ ğŸ“± app/
â”‚   â””â”€â”€ streamlit_app.py           # Application web (718 lignes)
â”‚
â”œâ”€â”€ ğŸ§© src/                         # Code rÃ©utilisable
â”‚   â”œâ”€â”€ data/loader.py              # Chargement artefacts
â”‚   â”œâ”€â”€ models/predictor.py         # PrÃ©dictions
â”‚   â”œâ”€â”€ models/explainer.py         # Explications SHAP
â”‚   â”œâ”€â”€ utils/validation.py         # Validation donnÃ©es
â”‚   â””â”€â”€ visualization/plots.py      # Graphiques Plotly
â”‚
â”œâ”€â”€ ğŸ§ª tests/                       # 22 tests unitaires
â”‚   â”œâ”€â”€ test_predictor.py           # 8 tests (95% coverage)
â”‚   â”œâ”€â”€ test_loader.py              # 4 tests (92% coverage)
â”‚   â””â”€â”€ test_validation.py          # 10 tests (88% coverage)
â”‚
â”œâ”€â”€ ğŸ““ notebooks/                   # Analyse et recherche
â”‚   â”œâ”€â”€ 01_eda.ipynb                # Exploration donnÃ©es
â”‚   â””â”€â”€ 02_preparation.ipynb        # ModÃ©lisation complÃ¨te
â”‚
â”œâ”€â”€ ğŸ› ï¸ scripts/                     # Automatisation
â”‚   â”œâ”€â”€ setup.sh                    # Installation auto
â”‚   â”œâ”€â”€ train_model.py              # EntraÃ®nement
â”‚   â””â”€â”€ predict.py                  # PrÃ©dictions CLI
â”‚
â””â”€â”€ ğŸ’¾ models/rf_smote_final/       # Artefacts ML
    â”œâ”€â”€ pipeline.joblib             # Pipeline sklearn
    â”œâ”€â”€ metrics_valid.json          # MÃ©triques
    â””â”€â”€ columns.json                # SchÃ©ma donnÃ©es

âœ… QUALITÃ‰ DU CODE
â€¢ Architecture modulaire (DRY principle)
â€¢ 22 tests unitaires (pytest)
â€¢ Documentation complÃ¨te (docstrings)
â€¢ Type hints pour clartÃ©
â€¢ Error handling robuste
```

### ğŸ“ Speech

> **L'architecture technique du projet a Ã©tÃ© conÃ§ue pour Ãªtre modulaire, maintenable et professionnelle.**
>
> **Le dossier `app/`** contient l'application Streamlit. Le fichier principal `streamlit_app.py` fait 718 lignes et orchestre tous les composants de l'interface utilisateur.
>
> **Le cÅ“ur du projet est le dossier `src/`** qui contient des modules rÃ©utilisables :
> - **data/loader.py** : GÃ¨re le chargement du pipeline, des mÃ©triques et des mÃ©tadonnÃ©es
> - **models/predictor.py** : Contient la classe FraudPredictor qui effectue les prÃ©dictions, gÃ¨re le preprocessing et le traitement par batch
> - **models/explainer.py** : ImplÃ©mente FraudExplainer pour les explications SHAP
> - **utils/validation.py** : DataValidator qui valide et nettoie les donnÃ©es d'entrÃ©e
> - **visualization/plots.py** : FraudVisualizer qui crÃ©e tous les graphiques Plotly
>
> Cette sÃ©paration permet de **rÃ©utiliser le code facilement** et de **tester chaque composant indÃ©pendamment**.
>
> **Le dossier `tests/`** contient **22 tests unitaires** avec pytest :
> - 8 tests pour le predictor (95% de couverture)
> - 4 tests pour le loader (92% de couverture)
> - 10 tests pour la validation (88% de couverture)
>
> Ces tests garantissent que chaque modification du code ne casse pas les fonctionnalitÃ©s existantes.
>
> **Les `notebooks/`** Jupyter documentent tout le processus de recherche :
> - `01_eda.ipynb` : L'exploration complÃ¨te des donnÃ©es avec toutes les visualisations
> - `02_preparation.ipynb` : Le preprocessing, la modÃ©lisation, la comparaison des algorithmes, et l'Ã©valuation finale
>
> **Les `scripts/`** automatisent les tÃ¢ches courantes :
> - `setup.sh` : Installation complÃ¨te du projet en une commande
> - `train_model.py` : EntraÃ®nement du modÃ¨le avec paramÃ¨tres configurables
> - `predict.py` : Interface en ligne de commande pour des prÃ©dictions rapides
>
> **Enfin, le dossier `models/`** stocke les artefacts ML :
> - Le pipeline sklearn complet avec preprocessing et modÃ¨le
> - Les mÃ©triques de validation au format JSON
> - Le schÃ©ma des colonnes attendues
>
> **Cette architecture respecte les bonnes pratiques** :
> - Principe DRY (Don't Repeat Yourself) : pas de duplication de code
> - Tests automatisÃ©s pour la fiabilitÃ©
> - Documentation exhaustive avec docstrings Google style
> - Type hints Python pour la clartÃ©
> - Gestion d'erreurs robuste avec fallbacks

**Transition** : *Terminons par les conclusions et perspectives d'amÃ©lioration.*

---

## SLIDE 14 : Conclusion et Perspectives

### ğŸ¯ Visuel
```
ğŸ¯ CONCLUSION

âœ… OBJECTIFS ATTEINTS
â€¢ ModÃ¨le performant : 87.84% Recall, PR-AUC 0.833
â€¢ Application web intuitive et interactive
â€¢ Explainability avec SHAP (IA responsable)
â€¢ Code de qualitÃ© production (tests, docs, architecture)

ğŸ’¡ APPORTS DU PROJET
â€¢ Traitement de donnÃ©es dÃ©sÃ©quilibrÃ©es (SMOTE)
â€¢ Optimisation de seuil adaptÃ©e au mÃ©tier
â€¢ Pipeline ML complet de bout en bout
â€¢ Application dÃ©ployable en production

ğŸš€ PERSPECTIVES D'AMÃ‰LIORATION

Court Terme (0-3 mois)
â€¢ DÃ©ploiement cloud (Streamlit Cloud / AWS)
â€¢ API REST pour intÃ©gration systÃ¨me bancaire
â€¢ Monitoring des prÃ©dictions en production
â€¢ Alerting automatique (email/SMS pour CRITIQUE)

Moyen Terme (3-6 mois)
â€¢ RÃ©entraÃ®nement automatique mensuel
â€¢ DÃ©tection de drift des donnÃ©es
â€¢ Dashboard analytics pour managers
â€¢ A/B testing de nouveaux modÃ¨les

Long Terme (6-12 mois)
â€¢ Deep Learning (LSTM pour sÃ©quences temporelles)
â€¢ Features engineering avancÃ©
â€¢ DÃ©tection d'anomalies (Isolation Forest, Autoencoder)
â€¢ IntÃ©gration GraphDB (rÃ©seaux de fraude)
```

### ğŸ“ Speech

> **En conclusion, je suis fiÃ¨re de dire que tous les objectifs fixÃ©s ont Ã©tÃ© atteints.**
>
> **Nous avons dÃ©veloppÃ© un modÃ¨le performant** avec un Recall de 87.84% et un PR-AUC de 0.833, ce qui est excellent pour des donnÃ©es aussi dÃ©sÃ©quilibrÃ©es. **L'application web** est intuitive et accessible aux non-techniciens. **L'explainability est garantie** grÃ¢ce aux explications SHAP, rÃ©pondant aux exigences d'IA responsable. Et **le code est de qualitÃ© production** avec tests, documentation et architecture modulaire.
>
> **Les apports de ce projet sont multiples** :
> - J'ai maÃ®trisÃ© le traitement de donnÃ©es extrÃªmement dÃ©sÃ©quilibrÃ©es avec SMOTE
> - J'ai appris Ã  optimiser un seuil de dÃ©cision en fonction des besoins mÃ©tier (maximiser le Recall)
> - J'ai dÃ©veloppÃ© un pipeline ML complet de A Ã  Z
> - J'ai crÃ©Ã© une application dÃ©ployable en production
>
> **Mais ce projet n'est qu'un dÃ©but. Voici les perspectives d'amÃ©lioration** :
>
> **Ã€ court terme**, dans les 0 Ã  3 mois :
> - **DÃ©ploiement cloud** sur Streamlit Cloud ou AWS pour rendre l'application accessible depuis internet
> - **DÃ©veloppement d'une API REST** pour permettre l'intÃ©gration dans les systÃ¨mes bancaires existants
> - **Mise en place de monitoring** pour suivre les performances du modÃ¨le en production
> - **Alerting automatique** par email ou SMS pour les transactions critiques
>
> **Ã€ moyen terme**, dans les 3 Ã  6 mois :
> - **RÃ©entraÃ®nement automatique** du modÃ¨le chaque mois avec les nouvelles donnÃ©es
> - **DÃ©tection de drift** pour identifier quand les patterns de fraude changent et que le modÃ¨le doit Ãªtre adaptÃ©
> - **Dashboard analytics** pour les managers avec KPIs et tendances
> - **A/B testing** pour comparer de nouveaux modÃ¨les en production
>
> **Ã€ long terme**, dans les 6 Ã  12 mois :
> - **Deep Learning** : utiliser des LSTM pour capturer les sÃ©quences temporelles de transactions
> - **Feature engineering avancÃ©** : crÃ©er de nouvelles variables Ã  partir des donnÃ©es brutes
> - **Techniques d'anomaly detection** comme Isolation Forest ou Autoencoders
> - **IntÃ©gration de bases de donnÃ©es graphes** pour dÃ©tecter les rÃ©seaux de fraude et les comportements collectifs suspects
>
> Ce projet dÃ©montre qu'avec une mÃ©thodologie rigoureuse et les bons outils, il est possible de rÃ©soudre des problÃ¨mes complexes de dÃ©tection de fraude tout en garantissant transparence et explainability.

**Transition** : *Je vous remercie pour votre attention.*

---

## SLIDE 15 : Questions et Remerciements

### ğŸ¯ Visuel
```
ğŸ’™ MERCI POUR VOTRE ATTENTION

[IMAGE : Carte bancaire]

ğŸ‘¥ REMERCIEMENTS
â€¢ M. DOUMI KARIM - Encadrant
â€¢ M. KHALID BENABBESS - Encadrant
â€¢ ESLSCA Paris - Campus Rabat
â€¢ ULB Machine Learning Group (dataset)

ğŸ“ CONTACT
Marie Chandeste Melvina J. H. Medetadji Migan
ğŸ“§ melvinamedetadji@gmail.com
ğŸ”— GitHub : github.com/Mariechanne/fraud-detection-pfe
ğŸ”— Kaggle : kaggle.com/melvinamedetadji

â“ QUESTIONS ?

ğŸ’¡ Je reste Ã  votre disposition pour toute question
   sur la mÃ©thodologie, les rÃ©sultats, l'application,
   ou les perspectives du projet.
```

### ğŸ“ Speech

> **Je vous remercie pour votre attention.**
>
> **Je tiens Ã  remercier chaleureusement** :
> - **Mes encadrants, Monsieur DOUMI KARIM et Monsieur KHALID BENABBESS**, pour leurs conseils prÃ©cieux et leur soutien tout au long de ce projet
> - **L'ESLSCA Paris, Campus Rabat**, pour la qualitÃ© de la formation en Data Science
> - **L'ULB Machine Learning Group** pour la mise Ã  disposition du dataset qui a rendu ce projet possible
>
> **Pour me contacter** :
> - Email : melvinamedetadji@gmail.com
> - Le code source complet est disponible sur mon GitHub : github.com/Mariechanne/fraud-detection-pfe
> - Mon profil Kaggle : kaggle.com/melvinamedetadji
>
> **Je suis maintenant Ã  votre disposition pour rÃ©pondre Ã  vos questions**, que ce soit sur :
> - La mÃ©thodologie Machine Learning utilisÃ©e
> - Les rÃ©sultats et performances du modÃ¨le
> - L'architecture de l'application
> - Les choix techniques effectuÃ©s
> - Les perspectives d'amÃ©lioration
> - Ou tout autre aspect du projet
>
> **Merci encore, et je serai ravie d'Ã©changer avec vous.**

---

## ğŸ“š ANNEXE : Questions FrÃ©quentes AnticipÃ©es

### Q1 : Pourquoi avoir choisi Random Forest plutÃ´t que XGBoost ?

**RÃ©ponse** :
> Excellente question. Bien que XGBoost soit souvent considÃ©rÃ© comme plus performant, dans notre cas, Random Forest s'est rÃ©vÃ©lÃ© supÃ©rieur pour trois raisons :
> 1. **Meilleur PR-AUC** (0.8646 vs 0.8528) : diffÃ©rence significative pour des donnÃ©es dÃ©sÃ©quilibrÃ©es
> 2. **Plus grande stabilitÃ©** : variance de Â±1.1% contre Â±2.0% pour XGBoost en cross-validation
> 3. **Meilleur F1-Score** (0.848 vs 0.825) : meilleur Ã©quilibre Recall/Precision
>
> De plus, Random Forest est plus simple Ã  interprÃ©ter et plus robuste au surapprentissage sans nÃ©cessiter autant de tuning d'hyperparamÃ¨tres.

### Q2 : Comment gÃ©rez-vous le risque de surapprentissage avec SMOTE ?

**RÃ©ponse** :
> Point trÃ¨s pertinent. Nous avons pris plusieurs prÃ©cautions :
> 1. **SMOTE uniquement sur le train set** : jamais sur validation ou test
> 2. **Cross-validation 5-fold** : validation robuste des performances
> 3. **Comparaison VALID â†” TEST** : les mÃ©triques sont cohÃ©rentes (ROC-AUC 0.9729 vs 0.9752), preuve qu'il n'y a pas de surapprentissage
> 4. **StratÃ©gie SMOTE modÃ©rÃ©e** : 0.2 (20% fraudes) au lieu d'Ã©quilibrer Ã  50/50, pour rester proche de la distribution rÃ©elle

### Q3 : 21% de Precision, n'est-ce pas trop faible ?

**RÃ©ponse** :
> C'est une excellente question qui touche au cÅ“ur du trade-off Recall vs Precision.
>
> Dans le contexte de la fraude bancaire, **manquer une fraude coÃ»te beaucoup plus cher qu'une fausse alerte**. Une fraude de 500â‚¬ non dÃ©tectÃ©e = 500â‚¬ de perte. VÃ©rifier une fausse alerte = quelques minutes d'un analyste.
>
> Avec 21% de Precision et 87.84% de Recall :
> - Nous dÃ©tectons **65/74 fraudes** (seulement 9 manquÃ©es)
> - Nous gÃ©nÃ©rons **243 fausses alertes** sur 42,647 transactions normales (0.57%)
> - Cela reprÃ©sente environ **50 fausses alertes par jour** pour une banque, ce qui est gÃ©rable
>
> Si nous augmentions le seuil pour avoir 50% de Precision, nous manquerions **20-25 fraudes supplÃ©mentaires**, ce qui serait inacceptable. Le seuil de 7.33% est optimisÃ© pour **maximiser le Recall avec une Precision minimale de 20%**, ce qui est un compromis standard dans l'industrie.

### Q4 : Comment le modÃ¨le gÃ¨re-t-il les nouvelles techniques de fraude ?

**RÃ©ponse** :
> C'est effectivement un dÃ©fi important. Nous avons prÃ©vu plusieurs stratÃ©gies :
>
> **Court terme** :
> - **Monitoring continu** : suivre les taux de dÃ©tection rÃ©els en production
> - **Feedback loop** : les analystes confirment ou infirment chaque alerte, ces donnÃ©es servent au rÃ©entraÃ®nement
>
> **Moyen terme** :
> - **RÃ©entraÃ®nement mensuel** : le modÃ¨le apprend les nouveaux patterns
> - **DÃ©tection de drift** : alertes automatiques si les distributions changent significativement
>
> **Long terme** :
> - **ModÃ¨les d'anomaly detection** (Isolation Forest, Autoencoder) qui dÃ©tectent des comportements jamais vus
> - **Transfer learning** : utiliser des modÃ¨les prÃ©-entraÃ®nÃ©s sur d'autres datasets de fraude
>
> Le modÃ¨le actuel capture les patterns gÃ©nÃ©raux de fraude (montants, features PCA), qui restent relativement stables, mais une surveillance active est essentielle.

### Q5 : Pourquoi ne pas utiliser de Deep Learning ?

**RÃ©ponse** :
> TrÃ¨s bonne question. Nous avons privilÃ©giÃ© Random Forest pour plusieurs raisons :
>
> 1. **Taille du dataset** : 284k transactions, c'est suffisant pour RF mais un peu limitÃ© pour DL qui nÃ©cessite des millions d'exemples pour vraiment exceller
>
> 2. **InterprÃ©tabilitÃ©** : Random Forest + SHAP offre des explications claires et prÃ©cises. Les rÃ©seaux de neurones sont plus opaques, ce qui est problÃ©matique dans le secteur bancaire rÃ©gulÃ©
>
> 3. **Temps d'entraÃ®nement** : RF s'entraÃ®ne en quelques minutes, DL prendrait des heures voire des jours
>
> 4. **Performances** : Avec PR-AUC de 0.833, nous avons dÃ©jÃ  d'excellentes performances. Le gain potentiel avec DL serait marginal
>
> **Cela dit**, dans les perspectives Ã  long terme, j'ai mentionnÃ© l'utilisation de **LSTM** pour capturer les sÃ©quences temporelles de transactions (par exemple, dÃ©tecter qu'un utilisateur fait 10 petites transactions suivies d'une grosse, ce qui est suspect). Cela ferait sens avec plus de donnÃ©es historiques par client.

### Q6 : Comment dÃ©ploieriez-vous ce modÃ¨le en production ?

**RÃ©ponse** :
> Voici l'architecture de dÃ©ploiement que je recommande :
>
> **Option 1 : API REST (RecommandÃ© pour intÃ©gration systÃ¨me)**
> ```
> Client (systÃ¨me bancaire)
>   â†’ API Flask/FastAPI
>   â†’ Load Balancer
>   â†’ Multiple instances du modÃ¨le
>   â†’ Base de donnÃ©es (logs + feedback)
> ```
>
> **Option 2 : Streamlit Cloud (Rapide pour POC)**
> - DÃ©ploiement en 1 clic sur Streamlit Cloud
> - AccÃ¨s web direct pour les analystes
> - Bon pour phase pilote
>
> **Option 3 : Conteneurisation Docker + Kubernetes**
> - ScalabilitÃ© automatique
> - Haute disponibilitÃ©
> - Convient aux grandes banques
>
> **Composants essentiels** :
> - **Monitoring** : Prometheus + Grafana pour suivre latence, throughput, taux de dÃ©tection
> - **Logging** : Toutes les prÃ©dictions dans une DB pour audit et rÃ©entraÃ®nement
> - **A/B testing** : Framework pour tester de nouveaux modÃ¨les sur 10% du trafic avant rollout complet
> - **Alerting** : PagerDuty/Slack pour transactions critiques
>
> Le code actuel est dÃ©jÃ  **production-ready** grÃ¢ce Ã  l'architecture modulaire et aux tests unitaires.

---

## ğŸ¯ CONSEILS POUR LA SOUTENANCE

### Avant la prÃ©sentation
1. **Tester l'application** : S'assurer qu'elle fonctionne parfaitement, avoir des exemples prÃ©-chargÃ©s
2. **PrÃ©parer les dÃ©mos** : Screenshots clairs, transitions fluides
3. **ChronomÃ¨tre** : Respecter le timing de chaque slide (25-30 min total)
4. **Backup plan** : PDF des notebooks en cas de problÃ¨me technique

### Pendant la prÃ©sentation
1. **Contact visuel** : Regarder le jury, pas seulement les slides
2. **Enthusiasm** : Montrer votre passion pour le projet
3. **ClartÃ©** : Utiliser des analogies pour expliquer les concepts techniques
4. **HonnÃªtetÃ©** : Admettre les limitations du projet, cela montre la maturitÃ©

### Pendant les questions
1. **Ã‰couter attentivement** : Reformuler la question si nÃ©cessaire
2. **Prendre son temps** : Respirer, rÃ©flÃ©chir 5 secondes avant de rÃ©pondre
3. **Structurer** : "Excellente question. Trois points : PremiÃ¨rement... DeuxiÃ¨mement... TroisiÃ¨mement..."
4. **HonnÃªtetÃ©** : Si vous ne savez pas, dites "C'est une excellente question, je n'ai pas explorÃ© cet aspect en dÃ©tail, mais voici ce que je pense..."

### Points Ã  souligner
- **Rigueur mÃ©thodologique** : CV 5-fold, split stratifiÃ©, optimisation de seuil
- **Gestion du dÃ©sÃ©quilibre** : SMOTE, PR-AUC comme mÃ©trique
- **IA responsable** : Explainability avec SHAP
- **QualitÃ© du code** : Tests, architecture, documentation
- **Vision produit** : Application dÃ©ployable, perspectives claires

---

**Bonne chance pour votre soutenance ! ğŸ“âœ¨**
