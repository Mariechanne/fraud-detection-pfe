# üõ†Ô∏è Guide D√©veloppeur - Syst√®me de D√©tection de Fraude

## üì¶ Architecture du Projet

### Modules R√©utilisables

Le projet est organis√© en modules Python r√©utilisables pour faciliter la maintenance et l'extension:

```
src/
‚îú‚îÄ‚îÄ data/          # Chargement des artefacts
‚îú‚îÄ‚îÄ models/        # Pr√©diction et explication
‚îú‚îÄ‚îÄ utils/         # Validation des donn√©es
‚îî‚îÄ‚îÄ visualization/ # Graphiques et visualisations
```

### Composants Principaux

#### 1. `src/data/loader.py` - Chargement des Artefacts

```python
from src.data.loader import ArtifactLoader

# Charger le mod√®le
loader = ArtifactLoader("models/rf_smote_final")
pipeline, metrics, columns, warnings = loader.load_artifacts()
```

**Responsabilit√©s:**
- Charger le pipeline sklearn
- Charger les m√©triques de validation
- Charger la liste des colonnes attendues
- V√©rifier la coh√©rence du mod√®le

#### 2. `src/models/predictor.py` - Pr√©dictions

```python
from src.models.predictor import FraudPredictor

# Initialiser le pr√©dicateur
predictor = FraudPredictor(pipeline, columns, threshold=0.073)

# Pr√©dire sur une transaction
transaction = {"Amount": 100.0, "Time": 500.0}
proba, pred = predictor.predict_single(transaction)

# Pr√©dire sur un DataFrame
probas, preds = predictor.predict(dataframe)

# Traiter un gros fichier par chunks
probas, preds = predictor.predict_batch(dataframe, chunk_size=5000)
```

**Responsabilit√©s:**
- Assurer la pr√©sence de toutes les colonnes
- Pr√©dire les probabilit√©s de fraude
- Appliquer le seuil de d√©cision
- G√©rer le traitement par batch

#### 3. `src/models/explainer.py` - Explications SHAP

```python
from src.models.explainer import FraudExplainer

# Initialiser l'explainer
explainer = FraudExplainer(pipeline)

# Expliquer une pr√©diction
features, error = explainer.explain(dataframe, top_k=5)

# Obtenir l'importance globale des features
importance = explainer.get_feature_importance()
```

**Responsabilit√©s:**
- Initialiser SHAP TreeExplainer
- Calculer les valeurs SHAP
- Extraire les features les plus importantes
- G√©rer les erreurs gracieusement

#### 4. `src/utils/validation.py` - Validation

```python
from src.utils.validation import DataValidator

# Initialiser le validateur
validator = DataValidator(expected_columns, max_rows=100_000)

# Valider un DataFrame
is_valid, errors = validator.validate_dataframe(dataframe)

# Valider une transaction
is_valid, errors = validator.validate_transaction(transaction)

# Nettoyer les donn√©es
clean_df = validator.sanitize_dataframe(dataframe)
```

**Responsabilit√©s:**
- V√©rifier la taille des fichiers
- Valider les colonnes requises
- V√©rifier les types de donn√©es
- Nettoyer et normaliser les donn√©es

#### 5. `src/visualization/plots.py` - Visualisations

```python
from src.visualization.plots import FraudVisualizer

# Cr√©er une jauge
fig = FraudVisualizer.create_gauge(value=0.073, title="Seuil")

# Cr√©er un graphique de probabilit√©
fig = FraudVisualizer.create_probability_bar(proba, threshold)

# Cr√©er un graphique SHAP
fig = FraudVisualizer.create_shap_bar(features)

# Cr√©er un histogramme
fig = FraudVisualizer.create_histogram(probabilities, threshold)

# Cr√©er un camembert des risques
fig = FraudVisualizer.create_risk_pie(risk_counts)
```

**Responsabilit√©s:**
- Cr√©er des graphiques Plotly coh√©rents
- Appliquer le style professionnel
- G√©rer les couleurs et le branding

---

## üß™ Tests

### Ex√©cuter les Tests

```bash
# Tous les tests
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=src --cov-report=html

# Tests d'un module sp√©cifique
pytest tests/test_predictor.py -v

# Tests avec mode verbose
pytest tests/ -vv
```

### √âcrire de Nouveaux Tests

```python
import pytest
from src.models.predictor import FraudPredictor

def test_my_feature():
    """Test ma nouvelle fonctionnalit√©."""
    # Arrange
    predictor = FraudPredictor(...)

    # Act
    result = predictor.my_method()

    # Assert
    assert result == expected_value
```

### Fixtures Pytest

```python
@pytest.fixture
def mock_pipeline():
    """Cr√©e un pipeline mock pour les tests."""
    # Votre code ici
    return pipeline

def test_with_fixture(mock_pipeline):
    """Utilise la fixture."""
    predictor = FraudPredictor(mock_pipeline, ...)
    # Votre test
```

---

## üîß D√©veloppement

### Configuration de l'Environnement

```bash
# Cr√©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

# Installer en mode d√©veloppement
pip install -e .
pip install -r requirements.txt

# Installer les outils de qualit√© de code
pip install black isort flake8 pytest
```

### Formatage du Code

```bash
# Black - Formattage automatique
black src/ tests/ scripts/

# isort - Trier les imports
isort src/ tests/ scripts/

# flake8 - Linter
flake8 src/ tests/ scripts/
```

### Conventions de Code

**Style:**
- Suivre PEP 8
- Max 100 caract√®res par ligne (configur√© dans `pyproject.toml`)
- Docstrings Google style

**Exemple de docstring:**
```python
def predict_single(self, transaction: dict) -> tuple[float, int]:
    """
    Pr√©dit si une transaction unique est frauduleuse.

    Args:
        transaction: Dictionnaire contenant les features

    Returns:
        Tuple (probabilit√©, pr√©diction)

    Raises:
        ValueError: Si les colonnes requises sont manquantes
    """
    pass
```

---

## üìä Pipeline ML

### Architecture du Pipeline

```
Donn√©es brutes (CSV)
    ‚Üì
S√©paration Train/Valid/Test (70/15/15)
    ‚Üì
Preprocessing (StandardScaler sur Amount & Time)
    ‚Üì
SMOTE (R√©√©quilibrage √† 20%)
    ‚Üì
RandomForest (100 arbres, max_depth=20)
    ‚Üì
Optimisation du seuil (Recall >= 85%)
    ‚Üì
Mod√®le final
```

### Hyperparam√®tres par D√©faut

```python
SMOTE:
  - sampling_strategy: 0.2
  - k_neighbors: 5

RandomForest:
  - n_estimators: 100
  - max_depth: 20
  - min_samples_split: 10
  - random_state: 42
  - n_jobs: -1

Preprocessing:
  - StandardScaler sur [Amount, Time]
  - V1-V28 non transform√©es (d√©j√† PCA)
```

---

## üöÄ D√©ploiement

### Option 1: Streamlit Cloud

```bash
# 1. Cr√©er requirements.txt minimal
# 2. Push sur GitHub
# 3. Connecter √† Streamlit Cloud
# 4. D√©ployer app/streamlit_app.py
```

### Option 2: Docker

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8501

CMD ["streamlit", "run", "app/streamlit_app.py"]
```

```bash
# Build
docker build -t fraud-detector .

# Run
docker run -p 8501:8501 fraud-detector
```

### Option 3: Serveur Local

```bash
# Avec gunicorn (pour production)
gunicorn -w 4 -b 0.0.0.0:8000 app:app

# Avec Streamlit (d√©veloppement)
streamlit run app/streamlit_app.py --server.port 8501
```

---

## üìà Am√©liorer le Mod√®le

### 1. Ajouter de Nouvelles Features

```python
# Dans le pipeline
feature_engineering = FunctionTransformer(add_features)
pipeline = Pipeline([
    ('features', feature_engineering),
    ('prep', preprocessor),
    ('smote', SMOTE()),
    ('model', RandomForestClassifier())
])
```

### 2. Tester d'Autres Algorithmes

```python
from xgboost import XGBClassifier

# Remplacer RandomForest par XGBoost
model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    scale_pos_weight=(y_train==0).sum()/(y_train==1).sum()
)
```

### 3. Optimiser les Hyperparam√®tres

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'model__n_estimators': [50, 100, 200],
    'model__max_depth': [10, 20, 30],
    'smote__sampling_strategy': [0.1, 0.2, 0.3]
}

grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='average_precision')
grid.fit(X_train, y_train)
```

---

## üêõ Debugging

### Logs Streamlit

```python
import streamlit as st

# Activer le debug
st.set_option('client.showErrorDetails', True)

# Logger des messages
st.write("Debug:", variable)
```

### Profiling

```python
import cProfile
import pstats

# Profiler une fonction
profiler = cProfile.Profile()
profiler.enable()

# Votre code
result = my_function()

profiler.disable()
stats = pstats.Stats(profiler)
stats.print_stats()
```

---

## üìö Ressources

- **Streamlit**: https://docs.streamlit.io/
- **Scikit-learn**: https://scikit-learn.org/
- **SHAP**: https://shap.readthedocs.io/
- **Imbalanced-learn**: https://imbalanced-learn.org/
- **Plotly**: https://plotly.com/python/

---

**Mainteneur**: Marie Chandeste Melvina J. H. Medetadji Migan
**Derni√®re mise √† jour**: Novembre 2025
